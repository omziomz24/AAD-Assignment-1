---
title: "AAD Assignment 1 - Group 26"
author: "Omar, Eloise, Alina, Sue"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(car)
library(dplyr)
library(ggplot2)
library(car)
```


#2.1 Descriptive Analysis of the Data Set

```{r }
# Load the data 
data <- read.csv("Assignt1_data.csv", header = TRUE)

# Summary Stas of the Original Data 
str(data) 
head(data)
dim(data) 
summary(data)

# Cleaning data 
sum(rowSums(is.na(data)) > 0) 
# 190 out of 18640 rows with na values in aveBedrooms 
clean_data <- na.omit(data) # remove na rows 

# Summary Stats 
str(clean_data) 
head(clean_data)
dim(clean_data) 
summary(clean_data)
```



#2.1 Descriptive analysis of the data set

```{r }
data <- read.csv("Assignt1_data.csv")

# Summary stuff
str(data) 
summary(data)
head(data)
dim(data) 

# NA's
incomplete_rows <- data[!complete.cases(data), ] # these are all missing aveBedrooms.
data_clean <- na.omit 


# no duplicates
library(dplyr) 
data2 <- distinct(data) # no duplicates
  

# initial plots
target_col <- "medianHouseValue"
exclude <- c("id","oceanProximity",target_col)

for (col in names(data)) {
  if (!(col %in% exclude)) {
    plot(data[[col]], data[[target_col]],
         xlab = col,
         ylab = target_col,
         main = paste(col, "vs", target_col))
  }
}


```

```{r}
# Some correlations 
summary(data_naomit) 
numeric.data <- data_naomit[sapply(data_naomit, is.numeric)]
View(numeric.data)
cor_medianHouseValue <- cor(data_naomit$medianHouseValue, 
                            data_naomit[, c("longitude", 
                                            "latitude", 
                                            "housingMedianAge",
                                            "aveRooms",
                                            "aveBedrooms",
                                            "population",
                                            "medianIncome")])
print(cor_medianHouseValue)
```

## Some Discriptives on Response (medianHouseValue) 
```{r}
hist(data_naomit$medianHouseValue,
     xlab = "Median House Value ($)",
     ylab = "Frequency",
     main = "Hostogram of Median House Value",
     breaks = 25)
```








# For plots
```{r, echo=FALSE}

data_naomit <- na.omit(data)

# Pairwise scatter plots 
pairs(data_naomit[, c("longitude", "latitude", "housingMedianAge", 
                      "aveRooms", "population", "medianIncome", "medianHouseValue")],
      cex = 0.1)
```

## Some other plots 
```{r}




```







2Fc27cKCitvAnJb


# Multiple Linear Regression 

## Using all predictors (id is not a predictor)

The p-value of the F-test is practically zero, therefore we have sufficient evidence to reject the null hypothesis that all regression coefficients are zero. This means that the model has overall significance, and that at least one of the predictors are useful in explaning the variation in the response variable (i.e. medianHouseValue). 

Having concluded that this model (fit1_MHV) has overall significance, we can gauge the significance of individual predictors through the t-test p-values. It is clear that population is not useful, as we do not have sufficient evidence to reject the null hypothesis that its corresponding coefficient is non-zero. The dummy variable, "NEAR BAY", associated to the categorical predictor, "oceanProximity", is also shown to be insignificant. This might be an indication that comparing to the base case (<1H OCEAN), NEAR BAY does not lead to significant change in Median House Price. 
```{r}
fit1_MHV <- lm(data_naomit$medianHouseValue ~. - id, data = data_naomit)
summary(fit1_MHV)
```

## Residual plot etc 
```{r}
par(mfrow = c(2,2))
plot(fit1_MHV, cex = 0.1)
```

## Outliers 
```{r}

```

## High Leverage Points 
```{r}

```

## Collinearity 
The arbitrary threshold of severe collinearity is vif greater or equal to 5. Here, 
all the predictors are shown to have a non-severe VIF. 
```{r}
vif(fit1_MHV)
```




